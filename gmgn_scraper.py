from spoon_ai.tools import BaseTool
from playwright.async_api import async_playwright
import json

class GmgnScraperTool(BaseTool):
    # Tool çš„å”¯ä¸€æ ‡è¯†ç¬¦ï¼ŒAgent é€šè¿‡è¿™ä¸ªåå­—è°ƒç”¨
    name: str = "get_gmgn_token_data"
    
    # æè¿° Tool çš„åŠŸèƒ½ï¼ŒPrompt Engineering çš„ä¸€éƒ¨åˆ†
    description: str = "Fetches real-time token data (price, volume, holders) from gmgn.ai for a given Solana token address."
    
    # å®šä¹‰å‚æ•°ç»“æ„ (JSON Schema)
    parameters: dict = {
        "type": "object",
        "properties": {
            "token_address": {
                "type": "string",
                "description": "The Solana contract address (CA) of the token."
            }
        },
        "required": ["token_address"]
    }

    async def execute(self, token_address: str):
        # ç®€å•çš„å®‰å…¨æ ¡éªŒï¼šSolana åœ°å€é€šå¸¸æ˜¯ Base58 ç¼–ç ï¼Œé•¿åº¦ 32-44
        import re
        if not re.match(r'^[1-9A-HJ-NP-Za-km-z]{32,44}$', token_address):
            return "Error: Invalid Solana token address format."

        url = f"https://gmgn.ai/sol/token/{token_address}"
        print(f"ğŸ¥„ SpoonOS Tool: Navigating to {url}...")
        
        async with async_playwright() as p:
            # å¯åŠ¨æ— å¤´æµè§ˆå™¨ï¼Œè®¾ç½® User-Agent è§„é¿åŸºç¡€åçˆ¬
            browser = await p.chromium.launch(headless=True)
            context = await browser.new_context(
                user_agent="Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
            )
            page = await context.new_page()
            
            try:
                # è®¿é—®é¡µé¢
                # GMGN æ•°æ®é¢‘ç¹åˆ·æ–°ï¼Œnetworkidle å®¹æ˜“è¶…æ—¶
                # æ”¹ä¸ºç­‰å¾… DOM åŠ è½½å®Œæˆ + å›ºå®šå»¶æ—¶ç­‰å¾…æ•°æ®æ¸²æŸ“
                await page.goto(url, timeout=60000)
                await page.wait_for_load_state("domcontentloaded")
                print("ğŸ¥„ SpoonOS Tool: Page loaded, waiting for data hydration...")
                await page.wait_for_timeout(5000) # ç­‰å¾… 5 ç§’è®© React æ¸²æŸ“å’Œæ•°æ®å¡«å……

                # æ¨¡æ‹Ÿç”¨æˆ·æ»šåŠ¨ä»¥è§¦å‘æ‡’åŠ è½½ï¼ˆå¦‚æœéœ€è¦ï¼‰
                # await page.mouse.wheel(0, 500)
                
                # --- è·å–é¡µé¢å¯è§æ–‡æœ¬å†…å®¹ ---
                # ç›´æ¥è·å– body.innerTextï¼Œè®© LLM å»åšç»“æ„åŒ–åˆ†æ
                content = await page.evaluate("() => document.body.innerText")
                
                # ç®€å•æ¸…æ´—ï¼šå»é™¤è¿‡å¤šç©ºè¡Œ
                cleaned_content = "\n".join([line.strip() for line in content.split('\n') if line.strip()])
                
                # æˆªå–å‰ 4000 å­—ç¬¦ (è§† Context Window è€Œå®šï¼Œæˆ–è€…å…¨éƒ¨è¿”å›)
                # è¿™é‡Œè¿”å›å…¨éƒ¨ï¼Œç”± Agent è‡ªè¡Œå†³å®šå¦‚ä½•å¤„ç†
                return cleaned_content

                
            except Exception as e:
                return f"Error scraping GMGN: {str(e)}"
            finally:
                await browser.close()
