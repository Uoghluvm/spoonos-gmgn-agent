from spoon_ai.tools.base import BaseTool, ToolResult
from playwright.async_api import async_playwright
import json
from typing import Any, Dict

class GmgnScraperTool(BaseTool):
    # Tool çš„å”¯ä¸€æ ‡è¯†ç¬¦ï¼ŒAgent é€šè¿‡è¿™ä¸ªåå­—è°ƒç”¨
    name: str = "get_gmgn_token_data"
    
    # æè¿° Tool çš„åŠŸèƒ½ï¼ŒPrompt Engineering çš„ä¸€éƒ¨åˆ†
    description: str = "Fetches real-time token data (price, volume, holders) from gmgn.ai for a given Solana token address."
    
    # å®šä¹‰å‚æ•°ç»“æ„ (JSON Schema)
    parameters: dict = {
        "type": "object",
        "properties": {
            "token_address": {
                "type": "string",
                "description": "The contract address (CA) of the token, OR the full GMGN.ai URL (e.g., https://gmgn.ai/sol/token/xyz)."
            },
            "chain": {
                "type": "string",
                "enum": ["sol", "bsc", "eth", "base", "blast", "tron"],
                "default": "sol",
                "description": "The blockchain network code. Ignored if a full URL is provided."
            }
        },
        "required": ["token_address"]
    }

    async def execute(self, token_address: str, chain: str = "sol") -> ToolResult:
        import re
        
        # 1. URL Mode
        if token_address.startswith("http"):
            url = token_address
            # Optional: Extract chain/address for logging or validation, but we trust the URL primarily
            print(f"ğŸ¥„ SpoonOS Tool: Using direct URL: {url}")
            # Basic validation to ensure it's gmgn
            if "gmgn.ai" not in url:
                 return ToolResult(error="Error: The provided URL is not a valid GMGN.ai URL.")
        else:
            # 2. Address Mode (Legacy)
            # é“¾ä¸åœ°å€æ ¼å¼çš„æ ¡éªŒé€»è¾‘
            is_evm = chain in ["bsc", "eth", "base", "blast"]
            is_sol = chain == "sol"
            is_tron = chain == "tron"

            valid = False
            if is_sol:
                # Solana: Base58, 32-44 chars
                if re.match(r'^[1-9A-HJ-NP-Za-km-z]{32,44}$', token_address):
                    valid = True
            elif is_evm:
                # EVM: Hex, starts with 0x, 42 chars total
                if re.match(r'^0x[a-fA-F0-9]{40}$', token_address):
                    valid = True
            elif is_tron:
                # Tron: Starts with T, 34 chars
                if re.match(r'^T[a-zA-Z0-9]{33}$', token_address):
                    valid = True
            
            if not valid:
                return ToolResult(error=f"Error: Invalid token address format for chain '{chain}'.")

            url = f"https://gmgn.ai/{chain}/token/{token_address}"
            print(f"ğŸ¥„ SpoonOS Tool: Constructed URL {url} from address")
        
        # Common Scraper Logic
        print(f"ğŸ¥„ SpoonOS Tool: Navigating to {url}...")
        
        async with async_playwright() as p:
            # å¯åŠ¨æ— å¤´æµè§ˆå™¨ï¼Œè®¾ç½® User-Agent è§„é¿åŸºç¡€åçˆ¬
            browser = await p.chromium.launch(headless=True)
            context = await browser.new_context(
                user_agent="Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
            )
            page = await context.new_page()
            
            try:
                # è®¿é—®é¡µé¢
                # GMGN æ•°æ®é¢‘ç¹åˆ·æ–°ï¼Œnetworkidle å®¹æ˜“è¶…æ—¶
                # æ”¹ä¸ºç­‰å¾… DOM åŠ è½½å®Œæˆ + å›ºå®šå»¶æ—¶ç­‰å¾…æ•°æ®æ¸²æŸ“
                await page.goto(url, timeout=60000)
                await page.wait_for_load_state("domcontentloaded")
                print("ğŸ¥„ SpoonOS Tool: Page loaded, waiting for data hydration...")
                await page.wait_for_timeout(5000) # ç­‰å¾… 5 ç§’è®© React æ¸²æŸ“å’Œæ•°æ®å¡«å……

                # æ¨¡æ‹Ÿç”¨æˆ·æ»šåŠ¨ä»¥è§¦å‘æ‡’åŠ è½½ï¼ˆå¦‚æœéœ€è¦ï¼‰
                # await page.mouse.wheel(0, 500)
                
                # --- è·å–é¡µé¢å¯è§æ–‡æœ¬å†…å®¹ ---
                # ç›´æ¥è·å– body.innerTextï¼Œè®© LLM å»åšç»“æ„åŒ–åˆ†æ
                content = await page.evaluate("() => document.body.innerText")
                
                # ç®€å•æ¸…æ´—ï¼šå»é™¤è¿‡å¤šç©ºè¡Œ
                cleaned_content = "\n".join([line.strip() for line in content.split('\n') if line.strip()])
                
                return ToolResult(
                    output=cleaned_content,
                    system="Successfully scraped GMGN data."
                )
                
            except Exception as e:
                return ToolResult(error=f"Error scraping GMGN: {str(e)}")
            finally:
                await browser.close()
